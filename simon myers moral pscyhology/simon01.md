Thank you Simon!  I’m interested in part because you’re presenting a very nice
account of how a single-process model might explain results that would otherwise
appear to support dual-process models. I’m also interested because it links to something
I’ve been thinking about with Corrado Sinigaglia in research on action. 

# The Core Claim

My first thought is that it would be good to separate your core idea from 
details about implementation.  The idea is to start with something less controversial
and work towards the more controversial part of the theory.

I think you are committed to these claims:

> 1. Means selection is a process which starts with a specified goal and samples actions that might
>   achieve the goal, eliminating actions that do not meet a *value threshold* 
>
> 1. There is a trade-off between having a high value threshold and selecting means rapidly.
>
> 1. In general, reducing time available requires reducing the value threshold[^key-idea]

[^key-idea]: I interpret this as supported by your suggestion that ‘More time means that more simulation and outcome testing can happen so people could converge on the previously discarded actions (with the threshold lowered) if they end up being comparatively better’.

I think you could make an exactly analogous claim substituting *value* for *effort*
(where means that require too much effort are discarded). 
The analogous claim wouldn’t be quite right: surely given a goal, means-selection aims 
to balance effort required against how likely a means is to achieve the goal. 
You can save a lot of effort in washing-up if you’re prepared to reduce the 
probability that your chosen means will succeed.
Another concern is that we seem to be committing a claim about thresholds when
we don’t know a lot about how the process works.

But there’s maybe a way to avoid these commitments while holding on to 
what’s important in the idea.

Suppose we think about means selection as a process of attempting to find the best
available balance between how demanding an action is and how well-suited 
to achieving the specified goal it is.  Then  I take your **core claim** to be 
that **demandingness should be understood not only in terms of factors like 
effort and risk of harm but also moral permissibility**.[^dec-th]

[^dec-th]: When Corrado and I made a version of this claim in a paper on cooperation 
    that was rejected (‘different actions you could perform may require more or 
    less effort, incur differing risks of harm to you, and impose varying levels of collateral damage; they 
    may also differ in how unpleasant or wrong they are, and so on’), we got hammered by a reviewer
    who thought it should all be understood as ‘cost’. 

This is a claim about which function describes means selection rather than
a claim about how it is implemented.

I take it that this is an interesting and quite bold claim, and that it is also
going to be less controversial than claims about implementation.  Do you agree with this?
And do you agree that this is the core claim, or have I misunderstood something important?


# The Target Predictions

Here are the early predictions I interpret you as aiming to derive from the overall view
(whether or not they follow just from what I’m calling the core claim):

> 1. Reducing time available, or increasing cognitive load, will result in a less good balance between 
>   well-subtends and moral permissibility.
>
> 1. Reducing time available, or increasing cognitive load, will result in moral permissibility
>   being evaluated using a faster, less sophisticated model. (This is good because it provides 
>   the basis for a link to emotion. It also makes it a bit hard to see were a single-process
>   theory ends and a dual-process one begins. Am I smuggling too much in here?)
>
> 1. Reducing time available, or increasing cognitive load, will result in moral permissibility
>  being evaluated in a way that emphasizes rules more and consequences less.[^si-sample]
>
> 1. Explicitly requiring people to consider impermissible options will result in them
>  considering a wider range of means.[^si-drop]
>
> 1. Some means can be identified as morally impermissible with relatively little processing
>   whereas others can only be identified as morally impermissible given more processing.
>
> 1. When someone selects a means to achieving a goal that is morally impermissible, the amount of
>   processing required to identify it as morally impermissible can serve as a mitigating factor.

[^si-sample]: I take this to follow from your claim that ‘Cognitive load also leads to more deontological decisions which again, on this model, means favouring decisions that automatically reject prohibited actions (since to end up considering those actions requires many more sampling trials)’

[^si-drop]: I take this to follow from your claim that ‘In a think-allowed task, one would predict that give the footbridge dilemma people will more actively consider other options than in the switch dilemma.’

From this last prediction, it’s probably not a huge step to make the link to partner choice.

I think there might be interesting connections with ideas about action understanding, 
particularly the idea that predicting or understanding others’ actions involves processes 
of simulation.