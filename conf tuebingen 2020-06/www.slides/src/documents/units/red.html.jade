---
layout: 'deck_unit'
title: "Red"
tags: []
description: "Reflection on redness suggests that we should be cautious about linking (a) psychological capacities, (b) phenomenology of folk colour, and (c) facts about colour."
depends: ['']
source: ['']
duration: 5
book: []
exercises: []
exercises_fast: []
---

include ../../../fragments/unit_mixins


+slide_middle
  p.center.huge-glow objection 1 : red

section.slide
  .notes: :t
    Let me start with something quite basic.
    Here are three patches of colour.
    The patches are all different colours, but the two leftmost are both the same colour---they are both blue.
    This sounds contradictory but isn't.
    In one case we're talking about the particular colours of things; in the other case we're talking about colour category.
  .notes: :t
    The question I want to ask about knowledge of colour concerns these cateories. 
    You know that these two are both blue whereas this is not (it's green).
    How do you come to know this?
    (Ask them to discuss.)
    Does anyone thing the answer is that you can just see it?  As we'll see, that idea looks promising initiall but it's not quite that simple.
  .notes: :t
    *TODO*: \citep{webster:2012_color} has good summary and lots of complications about CP.
    Also introduces methods not considered here.
  .words: .container_12: .grid_12
    p.hide What is categorical perception of colour?
  .middle
    .container_12
      .grid_4
        +colour-box('rgb(51,153,255)', 100)
        p.center 2.5B
      .grid_4
        +colour-box('rgb(85,100,255)', 100)
        p.center 7.5BG
      .grid_4
        +colour-box('rgb(42,162,42)', 100)
        p.center 2.5BG

+slide
  +img_clip('witzel_gegenfurtner_2013_fig6.png')
  p.source Witzel & Gegenfurtner, 2013 figure 6
  .notes: :t
    caption:
    ‘Figure 6. Color naming. The colors in the graphic refer to the color names used for a particular test color in a particular session by a particular observer. The x-axis refers to the variation in hue as in Figure 3. Each column refers to a particular stimulus color at isoluminance. The horizontal black lines separate layers that correspond to the data for each participant. Within each layer, the rows represent repeated measurements of color naming in different experimental sessions. Vertical black lines correspond to the category boundaries calculated through the modes of the single measurements. Supplementary Figure S6 provides the graphic for dark and light. Variation across was higher than within observers.’

+slide({bkg:'visual_pathway.jpg'})
  .notes: :t
    Can measure disciminability by different mechanisms.
  .notes: :t
    [a] ‘cone–opponent dimensions of the second-stage mechanisms can be
    used as a perceptual reference’
  .notes: :t
    [b] use discrimnation thresholds (JNDs) ‘the basic ability to
    detect small differences between colors. Sensitivity can be
    measured through discrimination thresholds’
  .notes: :t
    [c] use ‘a speeded, suprathreshold discrimination task


+slide
  +img_clip('witzel_2018_fig5.png', 'rect(0,380px,999px,0)')
  //- do not invert!
  //- +style('img', {filter:'invert(1)'})
  p.source Witzel & Gegenfurtner 2018, figure 5
  .notes: :t
    [caption:] ‘Category effects on color perception. (a) Categorical sensitivity. The diagram shows how the sensitivity to color differences changes across hue. The x-axis corresponds to hue in DKL color space, and the y-axis to discrimination thresholds. Adapted from Witzel & Gegenfurtner (2013). Note that the green-blue boundary is unlike the others in that it coincides with a local minimum of discrimination thresholds. (b) Categorical facilitation. The bars along the x-axis of the main graphic correspond to color pairs that are composed of the colors illustrated by the inset. The y-axis of the main graphic represents response times in speeded discrimination. Note that discriminating the color pair BC, in which B and C belong to different categories (i.e., red and brown), is fastest even though the distances between colors control for sensitivity to color differences. Adapted from Witzel & Gegenfurtner (2016). Abbreviation: DKL, Derrington-Krausfopf- Lennie. ∗∗p < 0.01; ∗∗∗p < 0.001.’
  .notes: :t
    \citep[p.~488]{witzel:2018_colora}: ‘First, the known
    cone–opponent dimensions of the second-stage mechanisms can be
    used as a perceptual reference, and the sensitivity to color
    differences can serve as the category-probing measure. We refer
    to the sensitivity to color differences as the basic ability to
    detect small differences between colors. Sensitivity can be
    measured through discrimination thresholds under optimal
    conditions. In case categorical perception acts even at this
    basic level, sensitivity should be higher—and thresholds
    lower—at the category boundaries than within the categories.
    However, this is not the case (cf. Figure 5a): There is no
    category effect at this low sensory level of color processing
    (Bachy et al. 2012; Cropper et al. 2013; Danilova & Mollon 2014;
    Roberson et al. 2009; Witzel & Gegenfurtner 2013, 2018).’
  .slide
    +clip('img', 'auto')
    .notes: :t
      \citep[p.~488]{witzel:2018_colora}: ‘Second, we can use those
      empirical discrimination thresholds as the perceptual
      reference and test for category effects on other performance
      measures (response times and error rates) in a speeded,
      suprathreshold discrimination task. In this case, category
      effects on response times and error rates have been observed
      around an isoluminant hue circle (Witzel & Gegenfurtner 2015)
      and at the red–brown boundary (Witzel & Gegenfurtner 2016)
      (see Figure 5b). We call these effects categorical
      facilitation in the sense that they facilitate speeded
      discrimination of suprathreshold stimuli beyond what is
      predicted by sensitivity. Interestingly, the categorical
      facilitation effects occurred only in na ̈ıve, unexperienced
      observers with high response times, but they disappeared for
      trained observers who became experts in the task and responded
      fast and automatically (Witzel & Gegenfurtner 2015).’

+slide({bkg:'slide_cp_40.jpg'})

+slide
  .notes.handout: :t
    ‘In the local market, we find: red, brown, white, and russet potatoes; red and green cabbages; red,
    yellow, and green bell peppers; red, yellow, and white onions; red and white grapes; white and pink
    grapefruit; red, white, black, green, and yellow beans; and, of course, red, white, rose, and green
    wine (green as in green Hungarian). Among hair colors, we find black, brown, red, blond (in­ stead of
    yellow), gray, and white. None of these nomenclatures makes sense if we go strictly by the standard
    Munsell color chips. The reds in red hair, red potatoes, red cabbage, red bell peppers, red onions,
    red grapes, red beans, red wine, and red skin are very different from the blood red of the focal red
    Munsell chip. They are also very different from each other. They only make sense with the similarity,
    preference, and exhaustiveness constraints. And these constraints couldn't work if it weren't for the
    principle of possibilities’ 
    \citep[p.~372]{clark:1992_arenas}.
  .colour
    p.step2.hide: :t
      ‘The reds in 
    p: :t
      red hair, red potatoes, red cabbage, red bell peppers, red onions,
      red grapes, red beans, red wine, and red skin 
    p.step2.hide
      span [...] only make sense with the similarity, 
      span preference, and exhaustiveness constraints. And these constraints couldn't work if it weren't for the 
      span.pop principle of possibilities
      span ’  
    p.right.grey-text Clark, 1992 p. 372
    .slide
      +show('.step2')
    .slide
      +highlight('.pop')
      p: :t
        ‘the principle of possibilities: We understand what an entity is with reference to 
        [... the set of possibilities we infer it came from’
  .slide
    +unhighlight('.pop')
    +blur('.colour')
    p.em-above As with colour, psychological terms like ‘acts’ and ‘thinks’ can be used to make many different contrasts ...
  .slide
    p.indent.hem-above ‘I know that my orchids are trying to stave off the cold so they can get growing again’
    p.indent.hem-above ‘This dormancy happens because the grass is trying to preserve itself with limited resources’
    p.indent.hem-above ‘spotify is trying to play’

+slide({bkg:'steward_figure.jpg'})

+slide_rh_white({fg:'steward_figure.jpg', fgOpacity:1})
  +left_half
    p(style='margin-top:400px') ‘some part of us finds it almost impossible not to categorise them as’ agents
    p.right.grey-text Steward, 2009 p. 229
  +right_half
    p(style='margin-top:150px') (my|your|his|her|their) phone
    p.indent is trying to (excluding ‘kill me’) [283,000]
    .notes: :t
      eg ‘my phone is trying to navigate me to Alex even though he has been deleted’
    p.indent wants to [278,000]
    p.indent hates [147,000]
    p.indent likes [86,800]
    p.indent thinks (e.g. ‘My phone thinks I’m in another city’) [53,400]
    p.indent is pretending [16,000]

